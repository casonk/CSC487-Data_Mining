---
title: '**CSC487**: Data Mining - Homework #2'
output:
  pdf_document:
    latex_engine: pdflatex
    extra_dependencies:
    - xcolor
    - hyperref
  word_document: default
  html_document:
    df_print: paged
fontsize: 12pt
graphics: yes
---

```{=latex}
\newcommand{\XB}{\color{black}}
\newcommand{\XBB}{\color{blue}}
\newcommand{\XV}{\color{violet}}
\newcommand{\XR}{\color{red}}

\begin{center}
  \XV\textit{\large{\href{https://github.com/casonk}{Cason Konzer}}}\XB \\
\end{center}
\hrulefill
\hfill
\newpage
```

```{r include=FALSE}
options(knitr.graphics.error = FALSE)

library(knitr)
library(ggplot2)
```

```{python include=FALSE}
import pandas as pd
import numpy as np
```


### 1. Find the distance between objects 1 and 3. Notice that we have mixed type of attributes. *(25 points)*

```{=latex}
\hrulefill

The following python code has will find the distance between any two objects for this dataset.
```

```{python}
# Build the dataframe.
table1 = {
  "Object Identifier": [1,2,3,4],
  "test-1 (nominal)" : ["A","B","C","A"],
  "test-2 (ordinal)" : ["excellent","fair","good","excellent"],
  "test-3 (numeric)" : [45,22,64,28]
  }
  
df1 = pd.DataFrame(table1)

# Set the index.
df1.set_index("Object Identifier",inplace=True)
df1
```

```{python}
# Replace nominal values.
df1["test-1 (nominal)"].replace("A",3,inplace=True)
df1["test-1 (nominal)"].replace("B",2,inplace=True)
df1["test-1 (nominal)"].replace("C",1,inplace=True)

t1_range = (df1["test-1 (nominal)"].max()-df1["test-1 (nominal)"].min())
df1["test-1 (nominal)"] = (df1["test-1 (nominal)"]-1)/t1_range
df1
```

```{python}
# Replace ordinal values.
df1["test-2 (ordinal)"].replace("excellent",3,inplace=True)
df1["test-2 (ordinal)"].replace("good",2,inplace=True)
df1["test-2 (ordinal)"].replace("fair",1,inplace=True)

t2_range = (df1["test-2 (ordinal)"].max()-df1["test-2 (ordinal)"].min())
df1["test-2 (ordinal)"] = (df1["test-2 (ordinal)"]-1)/t2_range
df1
```

```{python}
# Replace numeric values.
t3_range = (df1["test-3 (numeric)"].max()-df1["test-3 (numeric)"].min())
df1["test-3 (numeric)"] = (
  df1["test-3 (numeric)"]-df1["test-3 (numeric)"].min()
  )/t3_range
df1
```

```{python}
# Define our distance function.
def dist(i,j, df):
  neum = 0
  denom = 0
  for col in df.columns:
    print(col)
    if 'nominal' in col:
      if df[col].iloc[j-1] != df[col].iloc[i-1]:
        dist = 1
      else:
        dist = 0
    else:
      dist = np.abs(df[col].iloc[j-1] - df[col].iloc[i-1])
    print('feature distance:',dist)
    neum += dist
    denom += 1
    print()
  print('numerator:',neum)
  print('denomenator:',denom)
  print('\ntotal distance:')
  return neum/denom
  
# Compute the distance between object 1 & 3
dist(1,3, df1)
```

```{=latex}
We can see that the distance between object 1 and object 3 is \XBB $0.651$ \XB.

\newpage
```

### 2. Write a program in any language which can compute Manhattan and Euclidean distances between any two given vectors with any length. You can pass the length to your function, but please donâ€™t limit the dimension to 2. You can test your function on vectors you fill in your code without asking user input. *(25 points)*

```{=latex}
\hrulefill

The following python code has independent functions that will find the Manhattan and Euclidean distance between any two given numpy vectors.
```

```{python}
# Create test vector 1.
test_v1 = np.array([0,1,2,3,5,4])
test_v1
```

```{python}
# Create test vector 2.
test_v2 = np.array([1,0,3,2,4,6])
test_v2
```

```{python}
# Build our Manhattan Function
def manhattaan(v1,v2):
  return np.sum(np.abs(v2-v1))

# Test our Manhattan Function
manhattaan(test_v1,test_v2)
```

```{python}
# Build our Euclidean function.
def euclidian(v1,v2):
  return np.sqrt(np.sum(np.square(v2-v1)))

# Test our Euclidean function.
euclidian(test_v1,test_v2)
```


```{=latex}
We can see that the simple test vectors pass for both functions.

\newpage
```

### 3. In the table below, determine whether passing a class has a dependency on attendance by using Chi-square test. *(25 points)*

```{=latex}
\hrulefill
```

```{python}
# Build the dataframe.
table2 = {
  ""     : ["Attended","Skipped","Total"],
  "Pass" : [25,8,33],
  "Fail" : [6,15,21]
  }
  
df2 = pd.DataFrame(table2)
df2

```

```{python}
# Total on attendance status.
df2["Total"] = df2["Pass"] + df2["Fail"]
df2

```

```{python}
# Create an expectation dataframe as a copy of the original.
expectation_df2 = df2.copy()
expectation_df2
```

```{python}
# Compute probabilities on attendance status 
expectation_df2["Total"] = expectation_df2["Total"].apply(
  lambda x: x / expectation_df2["Total"].max()
  )
expectation_df2
```

```{python}
# Compute passing expectations.
expectation_df2["Pass"] = (
  expectation_df2["Pass"].max()*expectation_df2["Total"])
expectation_df2
```

```{python}
# Compute failing expectations
expectation_df2["Fail"] = (
  expectation_df2["Fail"].max()*expectation_df2["Total"])
expectation_df2
```

```{python}
# Trim our original dataframe.
df2 = df2.iloc[:-1,:-1]
df2
```

```{python}
# Trim our expectation dataframe
expectation_df2 = expectation_df2.iloc[:-1,:-1]
expectation_df2
```

```{python}
# Compute passing portion of chi squared.
pass_ = np.sum(
  np.square(
    (df2["Pass"] - expectation_df2["Pass"])
    )/expectation_df2["Pass"]
  )
pass_
```

```{=latex}
\newpage
```

```{python}
# Compute failing portion of chi square.
fail_ = np.sum(
  np.square(
    (df2["Fail"] - expectation_df2["Fail"])
    )/expectation_df2["Fail"]
  )
fail_
```

```{python}
# Sum for our chi squared value.
chi_squared_ = pass_ + fail_
chi_squared_
```

```{=latex}
We can see that we yield \XBB $\chi^2 = 11.686$ \XB.

\newpage
```

### 4. In R, there is a built-in data frame called `mtcars`. Please calculate the correlation between `mpg` and `wt` attributes of `mtcars` by using `cor()` function. Then generate scatter plot based on these two attributes. *(25 points)*

```{=latex}
\hrulefill
```

```{r message=TRUE, warning=FALSE}
# Preview mtcars dataset.
mtcars
```

```{=latex}
\newpage
```

```{r}
# Set variables for naming.
mpg = mtcars$mpg
weight = mtcars$wt
```

```{r}
# Find Correlation.
cor(mpg, weight)
```

```{=latex}
We can see that the correlation between vehicle miles per gallon and vehicle weight in the mtcars dataset is \XBB $r_{mpg,weight} =  -0.868 $ \XB .
What this explains is that as one variable (weight/mpg) increases, the other (mpg/weight) decreases.
```

```{r}
# Make scatterplot.
plot(mpg, weight)
```

```{=latex}
\newpage
```

```{r}
# To coincide with the example given in the assignment. (:
plot(weight, mpg)
```